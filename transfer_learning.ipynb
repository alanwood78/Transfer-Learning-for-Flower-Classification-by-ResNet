{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Training Dataset**: Data augmentation and normalization\n",
    "-  **Validation Dataset**: Normalization only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **RandomSizedCrop** used for data augmentation, cropping partial data from the original data to extend the size of the dataset, which makes the model more robust and sustainable. Each image are enlarged to size 224 after cropped.\n",
    "2. **RandomHorizontalFlip** used for data augmentation as well. Flip the original data horizotally to double the size of the dataset.\n",
    "3. **ToTensor** swap the axis of the original dataset for the purpose of training.\n",
    "4. **Normalize** takes a list of *average* and a list of *standard deviation* to complete normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "\t'train': transforms.Compose([\n",
    "\t\ttransforms.RandomSizedCrop(224),\n",
    "\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\t]),\n",
    "\t'val': transforms.Compose([\n",
    "\t\ttransforms.Scale(256),\n",
    "\t\ttransforms.CenterCrop(224),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\t]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "\t\t\t\t\t\t\t\t\t\t  data_transforms[x])\n",
    "\t\t\t\t  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "\t\t\t\t\t\t\t\t\t\t\t shuffle=True, num_workers=4)\n",
    "\t\t\t  for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up GPU by Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a batch of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloders['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a grid from batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a general function to train a model. Here, we will illustrate:\n",
    "\n",
    " -  Scheduling the learning rate\n",
    " -  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from ``torch.optim.lr_scheduler``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\tsince = time.time()\n",
    "\n",
    "\tbest_model_wts = model.state_dict()\n",
    "\tbest_acc = 0.0\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tprint('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\t\tprint('-' * 10)\n",
    "\n",
    "\t\t# Each epoch has a training and validation phase\n",
    "\t\tfor phase in ['train', 'val']:\n",
    "\t\t\tif phase == 'train':\n",
    "\t\t\t\tscheduler.step()\n",
    "\t\t\t\tmodel.train(True)  # Set model to training mode\n",
    "\t\t\telse:\n",
    "\t\t\t\tmodel.train(False)  # Set model to evaluate mode\n",
    "\n",
    "\t\t\trunning_loss = 0.0\n",
    "\t\t\trunning_corrects = 0\n",
    "\n",
    "\t\t\t# Iterate over data.\n",
    "\t\t\tfor data in dataloders[phase]:\n",
    "\t\t\t\t# get the inputs\n",
    "\t\t\t\tinputs, labels = data\n",
    "\n",
    "\t\t\t\t# wrap them in Variable\n",
    "\t\t\t\tif use_gpu:\n",
    "\t\t\t\t\tinputs = Variable(inputs.cuda())\n",
    "\t\t\t\t\tlabels = Variable(labels.cuda())\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tinputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "\t\t\t\t# zero the parameter gradients\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\t\t# forward\n",
    "\t\t\t\toutputs = model(inputs)\n",
    "\t\t\t\t_, preds = torch.max(outputs.data, 1)\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\n",
    "\t\t\t\t# backward + optimize only if in training phase\n",
    "\t\t\t\tif phase == 'train':\n",
    "\t\t\t\t\tloss.backward()\n",
    "\t\t\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t\t# statistics\n",
    "\t\t\t\trunning_loss += loss.data[0]\n",
    "\t\t\t\trunning_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\t\t\tepoch_loss = running_loss / dataset_sizes[phase]\n",
    "\t\t\tepoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "\t\t\tprint('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "\t\t\t\tphase, epoch_loss, epoch_acc))\n",
    "\n",
    "\t\t\t# deep copy the model\n",
    "\t\t\tif phase == 'val' and epoch_acc > best_acc:\n",
    "\t\t\t\tbest_acc = epoch_acc\n",
    "\t\t\t\tbest_model_wts = model.state_dict()\n",
    "\n",
    "\t\tprint()\n",
    "\n",
    "\ttime_elapsed = time.time() - since\n",
    "\tprint('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "\t\ttime_elapsed // 60, time_elapsed % 60))\n",
    "\tprint('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\t# load best model weights\n",
    "\tmodel.load_state_dict(best_model_wts)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/yao-chiehhu/.torch/models/resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GPU by Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "\tmodel_ft = model_ft.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decay the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/34\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
